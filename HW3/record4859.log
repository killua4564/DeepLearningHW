result	0.87700

index	loss			acc				val_loss		val_acc
1		2.292130099403	0.157460317843	2.279179193355	0.230370373638
2		2.264051569833	0.270952380366	2.243771067372	0.309259251312
3		2.214520189497	0.325873014000	2.175217584327	0.348518518386
4		2.121828741497	0.368730157614	2.047805706660	0.385555563150
5		1.956489125888	0.403968254725	1.838781003599	0.424074072529
6		1.722330636448	0.431746032503	1.573229343803	0.472592598862
7		1.473970717854	0.490476191044	1.339105765025	0.564444433760
8		1.263017482228	0.577301588323	1.189554814939	0.601851862890
9		1.116558624638	0.605079366101	1.062982952153	0.662962973118
10		1.011477066411	0.662222213215	1.000600236434	0.684444434113
11		0.963289380074	0.661746031708	0.922566669959	0.704444445946
12		0.896196689871	0.693968256315	0.889775342411	0.714444456277
13		0.844142781364	0.719523813989	0.823384329125	0.738148139583
14		0.793656263087	0.735555562708	0.777954426077	0.768888886328
15		0.747114042441	0.763968249162	0.745007360423	0.779629627864
16		0.700334370136	0.782698399491	0.699814546991	0.800370368693
17		0.658180369271	0.803015881115	0.680562752265	0.804814819936
18		0.632960988416	0.807936502828	0.660231031753	0.808518522316
19		0.609657009443	0.818730155627	0.623654796018	0.822222217366
20		0.587888697783	0.821269836691	0.619109615132	0.822222226196
21		0.567663987478	0.824285705884	0.613132066197	0.826666664194
22		0.549712631438	0.832063489490	0.603113106004	0.823703701849
23		0.535663538509	0.837301585409	0.591753672670	0.826296298592
24		0.521096918318	0.840317454603	0.571836608428	0.832592586676
25		0.501589546601	0.845714277691	0.565912078928	0.835185179004
26		0.487450225486	0.850317471557	0.554914397222	0.838888888006
27		0.489641884963	0.847619050079	0.566538770994	0.832962958901
28		0.478505664402	0.851587308778	0.554787955902	0.833703701143
29		0.473756664329	0.855714288023	0.559515100938	0.841851828275
30		0.452654851807	0.861587299241	0.537048935890	0.842222211538
31		0.439998997582	0.863174610668	0.543167019332	0.840740738092
32		0.431091871527	0.867142862744	0.533542803040	0.843703700436
33		0.420296539863	0.872222224871	0.529590773362	0.844444447094
34		0.409136510558	0.872857140170	0.520468375197	0.844814808280
35		0.399181293117	0.877460320791	0.519340515137	0.849629653825
36		0.391786658102	0.879206352764	0.511847138405	0.850740759461
37		0.381349484126	0.881111105283	0.514392289850	0.850740752838
38		0.375436786148	0.882539682918	0.504115241545	0.852962970734
39		0.368084635999	0.884603175852	0.503131911710	0.852222237322
40		0.359170463350	0.889365077019	0.500108839185	0.854814816404
41		0.353452579843	0.892380952835	0.502520310658	0.851111127271
42		0.344698101282	0.893015874757	0.491061874010	0.854814816404
43		0.339641971721	0.897301581171	0.492179302154	0.855925926456
44		0.331376098924	0.899841268857	0.488369060887	0.855555580722
45		0.326552573178	0.901111112701	0.489453308008	0.858518525406
46		0.328178786569	0.897936509715	0.493002869465	0.855555574099
47		0.333986626731	0.895714282990	0.498666786485	0.851481468589
48		0.370032211145	0.885079370605	0.529896049588	0.851481495080
49		0.354676233398	0.886349207825	0.485224701740	0.856296285435
50		0.350675231881	0.892063491874	0.485116259919	0.862592588972
51		0.337234599723	0.891904771328	0.472327511620	0.858888899838
52		0.327240082953	0.899999989404	0.475099292066	0.862222232200
53		0.311399704880	0.904920630985	0.461434242902	0.863703694608
54		0.306866904100	0.906666669581	0.466179784801	0.865555562355
55		0.297835969263	0.910158726904	0.457475379661	0.865555562355
56		0.288957241509	0.913333329890	0.462843903789	0.867037038008
57		0.286306063334	0.912698407968	0.452473349041	0.866666656953
58		0.309531791343	0.902222222752	0.472392132989	0.867407401403
59		0.292345394691	0.908412694931	0.456626483688	0.865555551317
60		0.280023646024	0.913015868929	0.453521316802	0.867407401403
61		0.268276479509	0.917301588588	0.453317078175	0.865555555732
62		0.264501414365	0.919523815314	0.447813145540	0.868148159098
63		0.258359586199	0.921269840664	0.446061119989	0.867777780250
64		0.252669440375	0.925555553701	0.444534954098	0.871481464969
65		0.248489800427	0.925238086118	0.450825325869	0.867407410233
66		0.243968750040	0.926825390922	0.443881617652	0.870740738180
67		0.240407379137	0.928412702348	0.447253879574	0.871111117027
68		0.241922363639	0.928730150064	0.446037577258	0.870370381408
69		0.242923711737	0.927619053258	0.448071582450	0.871851859269
70		0.237662504117	0.927777767181	0.447146946633	0.869259264734
71		0.234264292651	0.929523805777	0.450374361542	0.869629628128
72		0.229315289193	0.931111110581	0.448664860593	0.872592594888
73		0.225762282809	0.932698408763	0.455297381790	0.870370379201
74		0.220572077566	0.936031745540	0.442750244229	0.874444440559
75		0.216480801503	0.936507940292	0.452821496460	0.868888885887
76		0.226423680782	0.930317461491	0.550214902118	0.851851845229
77		0.366645932198	0.884126981099	0.517420673812	0.848888898337
78		0.297929969099	0.900952392154	0.474289522127	0.868888892509
79		0.262112074428	0.916190471914	0.460302963301	0.867037042424
80		0.238742272059	0.927619046635	0.446608459508	0.874074063919
81		0.272628487812	0.912380947007	0.453555224118	0.872222218249
82		0.262614708808	0.917460322380	0.459248488700	0.871851848231
83		0.228704738948	0.930317461491	0.453373166146	0.874444444974
84		0.217855720056	0.934126986398	0.449154350493	0.875925925043
85		0.214736666944	0.934444440736	0.463100151883	0.871481482629
86		0.221138031946	0.933492057853	0.448135271117	0.875185162933
87		0.209607394205	0.936984128422	0.448684630571	0.881481484131
88		0.203677493665	0.938253965643	0.448954623055	0.878518519578
89		0.202529016468	0.936825388008	0.446891884009	0.875925927250
90		0.196444335911	0.941111114290	0.440782120934	0.884074080873
91		0.190091031293	0.943492061562	0.439745727513	0.881481486338
92		0.184160911375	0.944285704030	0.440768130400	0.881481492961
93		0.181109241313	0.946666671170	0.446211669180	0.881111114113
94		0.259803839856	0.921746022171	0.469593405724	0.872962942830
95		0.230562102464	0.927936500973	0.455871263036	0.876666660662
96		0.201412134700	0.937301589383	0.454337979908	0.879259244159
97		0.184995790323	0.943333347638	0.447882938164	0.878888882973
98		0.177064014806	0.945555554496	0.445452970487	0.882222230788
99		0.171667812599	0.949047625065	0.440342296053	0.881851856355
100		0.167909009589	0.950793650415	0.442410917194	0.881851862978

max_length = 700
min_count=2, size=270, iter=10, sg=1, workers=10

LSTM(units=16, kernel_initializer=initializers.glorot_uniform(seed=1), activation='tanh')
Dense(units=100, kernel_initializer=initializers.glorot_uniform(seed=1), activation='relu')
Dense(units=100, kernel_initializer=initializers.glorot_uniform(seed=1), activation='relu')
Dense(units=10, kernel_initializer=initializers.glorot_uniform(seed=1), activation='softmax')

optimizer=optimizers.Adam(lr=.00052626)

model.fit(x=train_x, y=train_y, epochs=epochs, validation_split=.3, batch_size=700, verbose=1)
