result	

index	loss			acc				val_loss		val_acc
1		2.298388216231	0.123580248268	2.285058975220	0.165555551648
2		2.282117154863	0.170617286254	2.267732858658	0.184444442391
3		2.261941450614	0.204320984858	2.242925405502	0.211111113429
4		2.233149378388	0.237654321724	2.207271337509	0.252222210169
5		2.191723620450	0.268765436278	2.156926870346	0.268888890743
6		2.133088085386	0.291358016155	2.088494300842	0.302222222090
7		2.053654449957	0.307654323401	2.000139236450	0.307777792215
8		1.954072687361	0.324814817420	1.890488386154	0.327777773142
9		1.835922925561	0.352839496401	1.763977050781	0.372222214937
10		1.711572585283	0.399012345959	1.637946963310	0.458888888359
11		1.587382705123	0.465925933034	1.519669055939	0.515555560589
12		1.462835572384	0.539259263763	1.392157196999	0.571111083031
13		1.344018989139	0.598024683970	1.280772924423	0.624444425106
14		1.218048855110	0.640246914493	1.178049445152	0.655555546284
15		1.107833800492	0.678024704810	1.084470748901	0.670000016689
16		1.024345843880	0.699259259083	1.047098278999	0.674444437027
17		0.960167999621	0.709135810534	0.973831772804	0.698888897896
18		0.903358510247	0.726419755706	0.935359835625	0.704444468021
19		0.858956919776	0.733456786032	0.933905184269	0.717777788639
20		0.819345917967	0.747777779897	0.907579541206	0.723333358765
21		0.785504725244	0.755185204524	0.891774654388	0.727777779102
22		0.756983648848	0.766172830705	0.860737979412	0.736666679382
23		0.715145481957	0.779135810004	0.833154618740	0.744444429874
24		0.699892677643	0.786666662605	0.793575048447	0.755555570126
25		0.674420409732	0.799135810799	0.803511202335	0.763333320618
26		0.651427666346	0.807160514372	0.790763437748	0.767777800560
27		0.629779491160	0.813950629146	0.766694486141	0.767777800560
28		0.607110036744	0.818395047276	0.761456727982	0.767777800560
29		0.593054223944	0.821358000791	0.751495838165	0.775555551052
30		0.579465623255	0.826172846335	0.729025125504	0.781111121178
31		0.561529300831	0.833209876661	0.720694899559	0.790000021458
32		0.549152166755	0.836049386749	0.710583686829	0.797777771950
33		0.544974377862	0.837283964510	0.697277367115	0.795555531979
34		0.529801777116	0.838641983491	0.688941299915	0.798888862133
35		0.524118394763	0.839259255815	0.684614479542	0.800000011921
36		0.506981383871	0.846172853752	0.693089962006	0.808888912201
37		0.495977792475	0.849753088421	0.660133779049	0.806666672230
38		0.485292765829	0.851975330600	0.657192707062	0.805555582047
39		0.477019507576	0.858765425505	0.652982711792	0.811111092567
40		0.462033903157	0.862716045645	0.658761858940	0.811111092567
41		0.455576269715	0.861728409926	0.642350554466	0.813333332539
42		0.444112271070	0.866913598997	0.637946009636	0.814444422722
43		0.436186416282	0.868888901340	0.619668602943	0.821111083031
44		0.439814754106	0.866790111418	0.604645550251	0.819999992847
45		0.431086542430	0.874074061712	0.639015972614	0.825555562973
46		0.430245701913	0.875555539573	0.659963309765	0.812222242355
47		0.454942187777	0.861234565576	0.614508271217	0.829999983311
48		0.430336540496	0.871234567077	0.613470852375	0.828888893127
49		0.423485375113	0.873580221777	0.603963077068	0.829999983311
50		0.403019034200	0.879876558427	0.598444223404	0.833333313465
51		0.394612024228	0.881851862978	0.587608516216	0.831111133099
52		0.382231391139	0.886666679824	0.579893410206	0.831111133099
53		0.377986244581	0.888271594489	0.584506750107	0.834444463253
54		0.373068627384	0.888271596697	0.590300381184	0.829999983311
55		0.366417856128	0.891975318944	0.578208088875	0.837777793407
56		0.365041028570	0.891234550211	0.570018112659	0.839999973774
57		0.357625496608	0.894320982474	0.576501667500	0.836666643620
58		0.352960919892	0.895555531537	0.574614286423	0.845555543900
59		0.347266102279	0.895061726923	0.572358667850	0.834444463253
60		0.342077864541	0.898148139318	0.555062532425	0.836666643620
61		0.337534575551	0.899629654708	0.560097157955	0.846666693687
62		0.332689804059	0.900493831546	0.567028760910	0.836666643620
63		0.327004790306	0.901851837282	0.552329361439	0.842222213745
64		0.322800781992	0.904074057385	0.553054630756	0.842222213745
65		0.317509212980	0.905802461836	0.557379364967	0.844444453716
66		0.316043937648	0.906296297356	0.550974071026	0.843333303928
67		0.334327654706	0.899012349270	0.551753640175	0.841111123562
68		0.336966031128	0.898765418265	0.561358332634	0.846666693687
69		0.321566658991	0.904197531718	0.569015800953	0.845555543900
70		0.322513646550	0.903456802721	0.566928088665	0.847777783871
71		0.320038633214	0.903703722689	0.561936497688	0.848888874054
72		0.308150609334	0.907654311922	0.550131320953	0.843333303928
73		0.306743211216	0.908271599699	0.540940761566	0.845555543900
74		0.313761177990	0.905925925131	0.634192883968	0.823333323002
75		0.547747060105	0.838888883591	0.699992239475	0.785555541515
76		0.557167271773	0.824567889726	0.736011087894	0.754444420338
77		0.606670867514	0.781358027900	0.732308506966	0.776666641235
78		0.562371898580	0.820493823952	0.671886265278	0.768888890743
79		0.534863310832	0.819135791726	0.623820304871	0.810000002384
80		0.498525678008	0.843950633649	0.609027147293	0.819999992847
81		0.478741990195	0.848641987200	0.614779651165	0.814444422722
82		0.449029442337	0.862716054475	0.614747166634	0.806666672230
83		0.430962686185	0.867160492473	0.598192691803	0.815555572510
84		0.413022379080	0.874691353904	0.584550142288	0.827777802944
85		0.397564763272	0.879753081887	0.576258182526	0.834444463253
86		0.381467024485	0.884814831946	0.576505780220	0.832222223282
87		0.372570161466	0.886543214321	0.560525774956	0.835555553436
88		0.363738946341	0.890123479896	0.547166705132	0.837777793407
89		0.357705015827	0.890123442367	0.544814944267	0.837777793407
90		0.349722109459	0.894074077959	0.551870524883	0.839999973774
91		0.345015201304	0.896296284817	0.550450146198	0.837777793407
92		0.337313418035	0.898641972630	0.546888351440	0.841111123562
93		0.332528788734	0.899506160506	0.545908927917	0.841111123562
94		0.327330650003	0.901481473887	0.546588838100	0.847777783871
95		0.323707613680	0.902098759457	0.546002149582	0.839999973774
96		0.318664928277	0.903456774023	0.541604161263	0.842222213745
97		0.314641446979	0.905061726217	0.539279460907	0.843333303928
98		0.311379101541	0.906172849514	0.538713812828	0.842222213745
99		0.307967483997	0.907037046221	0.539574742317	0.842222213745
100		0.304774803144	0.908395078447	0.536784112453	0.842222213745

max_length = 200
min_count=2, size=270, iter=10, sg=1, workers=10

Embedding(input_dim=len(word_index)+1, output_dim=word2Vec.vector_size, weights=[embedding_matrix], input_length=max_length, trainable=False)
LSTM(units=16)
Dense(units=100, activation='relu')
Dense(units=100, activation='relu')
Dense(units=10, activation='softmax')

optimizer='adam'

model.fit(x=train_x, y=train_y, epochs=epochs, validation_split=.1, batch_size=3000, verbose=1)

