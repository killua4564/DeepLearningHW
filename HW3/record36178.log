result	0.60200

index	loss			acc				val_loss		val_acc
1		2.176646614453	0.316349212258	7.769821304745	0.000370370376
2		1.232750999123	0.563968259569	11.250013671098	0.000000000000
3		0.870039605527	0.705714288165	11.850686815050	0.000000000000
4		0.603684662892	0.787460315606	12.232806043272	0.000000000000
5		0.472446787924	0.838888884111	12.723874819720	0.000000000000
6		0.440772074672	0.858095232930	14.853710322910	0.000000000000
7		0.375006824313	0.876190469189	14.086657764294	0.000000000000
8		0.276553621952	0.911904754052	14.732064695711	0.000000000000
9		0.230638626717	0.929047611592	14.294291898939	0.000000000000
10		0.203775814274	0.941428564276	14.241612960674	0.000000000000
11		0.168541041058	0.951269834382	15.593962227857	0.000000000000
12		0.178555005224	0.947301580982	15.620710598981	0.000000000000
13		0.136426435401	0.961587296119	14.779305673529	0.000000000000
14		0.094894352085	0.975079360368	15.118981110608	0.000000000000
15		0.076215127951	0.981269837750	15.381871212853	0.000000000000
16		0.078472668619	0.978730154700	15.263970968458	0.000000000000
17		0.059315716976	0.984603171405	15.440446436847	0.000000000000
18		0.052830449193	0.987301584463	15.805649181649	0.000000000000
19		0.043749647407	0.986825394252	15.657554206142	0.000000000000
20		0.052466045179	0.983650790604	15.713626017394	0.000000000000

max_length = 700
min_count=2, size=270, iter=10, sg=1, workers=10

Embedding(input_dim=len(word_index)+1, output_dim=vector_size, weights=[embedding_matrix], input_length=max_length)
LSTM(units=200, kernel_initializer=initializers.RandomUniform(minval=-1, maxval=1, seed=1), activation='tanh', return_sequences=True, recurrent_activation='hard_sigmoid', unroll=True)
GRU(units=120, kernel_initializer=initializers.RandomUniform(minval=-1, maxval=1, seed=1), activation='relu', return_sequences=True, recurrent_activation='hard_sigmoid', unroll=True)
SimpleRNN(units=60, kernel_initializer=initializers.RandomUniform(minval=-1, maxval=1, seed=1), activation='tanh', return_sequences=False, unroll=True)
Dense(units=10, kernel_initializer=initializers.RandomUniform(minval=-1, maxval=1, seed=1), activation='softmax')

optimizer=optimizers.Adam(lr=.0012626)

model.fit(x=train_x, y=train_y, epochs=epochs, validation_split=.3, batch_size=10, verbose=1)
