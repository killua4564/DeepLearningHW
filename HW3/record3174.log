result	0.89900

index	loss			acc				val_loss		val_acc
1		1.993431131045	0.301428571225	1.463861337414	0.438888888668
2		1.327442759559	0.512698408630	1.050926848694	0.618148148060
3		1.081210780711	0.612222222582	0.873469202607	0.688888891980
4		0.885399918708	0.702222224266	0.726056390338	0.766666666225
5		0.777674587000	0.747936508012	0.635581038616	0.799629630866
6		0.680596383791	0.782063490815	0.588379183301	0.817777772744
7		0.583593612152	0.816825395539	0.519695213547	0.837777773539
8		0.551343436752	0.818253967497	0.486598663860	0.844814814903
9		0.492551511242	0.841111111262	0.446476628383	0.861111113319
10		0.466842441095	0.853333333182	0.414235088560	0.868518520285
11		0.425208602160	0.866507932307	0.415926002794	0.871851848231
12		0.412691258958	0.871428571996	0.403408440175	0.872592590473
13		0.399041380438	0.869523807177	0.373958000982	0.882962961992
14		0.368966785925	0.882222226688	0.369985446886	0.883333336424
15		0.355720889947	0.886031746864	0.353519848099	0.890000003356
16		0.351720009768	0.891587304691	0.343747468458	0.891481483424
17		0.331125106603	0.895238093914	0.356215577435	0.886666666578
18		0.323438813999	0.901428572715	0.341068697748	0.896296291440
19		0.302430496566	0.903492063757	0.341478293141	0.897407412529
20		0.301303055315	0.904920633823	0.342689447381	0.892222225666
21		0.279764250630	0.907301590556	0.329309948065	0.899999998234
22		0.274284522921	0.910158733527	0.334513667557	0.897037031474
23		0.256734402407	0.916984131412	0.346025347158	0.896296291440
24		0.259617672317	0.915873017576	0.340655991325	0.895555551405
25		0.254711018313	0.921269840664	0.324818833007	0.899259260407
26		0.244728590406	0.921746034471	0.328365876719	0.901851848320
27		0.226004097315	0.929365079554	0.320822646221	0.901851850527
28		0.231587881134	0.923174602645	0.319099374391	0.903703702821
29		0.221625961955	0.928412694780	0.323111207949	0.904074075045
30		0.214027583954	0.931111116258	0.321145216072	0.906666665166
31		0.208877632897	0.932698417278	0.328115198899	0.903333332804
32		0.210447286093	0.931269841535	0.324068503247	0.904074072838
33		0.201588249396	0.936349208393	0.346522917902	0.902222224960
34		0.188367737073	0.938888891349	0.324615278178	0.906296295148
35		0.181166989226	0.940634921430	0.321694858096	0.905185187304
36		0.189459832592	0.937301588437	0.328723773360	0.905185187304
37		0.179194270855	0.940793652383	0.352106324501	0.898888885975
38		0.183526616484	0.938888891349	0.335263963651	0.899259264822
39		0.175340330553	0.942857145317	0.334070477221	0.902962967202
40		0.174506549324	0.942857141533	0.314841960315	0.908888894099
41		0.168121336353	0.941269844297	0.328685566231	0.907407407407
42		0.150670938785	0.951269845168	0.330070091067	0.905925927339
43		0.150301005691	0.948412699359	0.335883764205	0.909629631926
44		0.145785352659	0.952698414288	0.342019713035	0.902962964994
45		0.134826272430	0.953492068109	0.350199747417	0.900740742683
46		0.138874556928	0.954285719092	0.359320981635	0.902962962786
47		0.131451604917	0.956666670148	0.359274701940	0.903703707236
48		0.136759701525	0.954603176268	0.352836136465	0.905555557322
49		0.128714570066	0.958888895928	0.360315219672	0.906296299564
50		0.129364089774	0.955238099136	0.360654041171	0.909999999735
51		0.122810703835	0.958412701175	0.367445419784	0.902592592769
52		0.122096641728	0.958253968330	0.365828211109	0.902592594977
53		0.122063808202	0.959206355943	0.359294103803	0.907037037390
54		0.113809228446	0.960793654124	0.370721817017	0.904444445063
55		0.121923546144	0.956984128271	0.381426312857	0.904814810665
56		0.113895341488	0.960000003141	0.379007521603	0.900740740476
57		0.121117120106	0.960317464102	0.371794778992	0.905555559529
58		0.106348697155	0.963650793310	0.370764777064	0.905185189512
59		0.102849504334	0.963174608019	0.386047932285	0.903333337219
60		0.096715983329	0.966507942904	0.377534622947	0.904814821702
61		0.105442556301	0.966190482889	0.380131270598	0.904444445063
62		0.098685104193	0.965555560021	0.394608922027	0.907037035183
63		0.098097502062	0.967142862933	0.395033564281	0.905925922924
64		0.090975036697	0.968730165845	0.394587945055	0.906666671788
65		0.096790900897	0.965873023820	0.392643630505	0.908888896306
66		0.095512651410	0.967936512024	0.401849873088	0.903703702821
67		0.095396865337	0.969682549673	0.402484830331	0.904814812872
68		0.083128333358	0.970476197818	0.393379050272	0.904444445063
69		0.089895926061	0.970634927825	0.415029954027	0.901111108285
70		0.088208499438	0.969682545889	0.422225775542	0.902222222752
71		0.080226641414	0.970634930664	0.421649295975	0.905925927339
72		0.073961445707	0.975714291845	0.434397061666	0.897777784754
73		0.076869280092	0.974761913693	0.447441742928	0.898518520373
74		0.085295274410	0.972857153605	0.432972059206	0.905555563944
75		0.085064748657	0.969682543051	0.425199089779	0.901851850527
76		0.077395795667	0.973809531757	0.433213743899	0.900000000442
77		0.079739127633	0.972222233575	0.415215934868	0.905555552906
78		0.084348718931	0.970317466865	0.431281882856	0.899629630424
79		0.089893135641	0.967460324840	0.432819522089	0.902222224960
80		0.071188957563	0.976507941882	0.425505925660	0.905555559529
81		0.080827910926	0.970952389732	0.443124164586	0.905555555114
82		0.080944609666	0.972539692644	0.452635386476	0.899629626009
83		0.073665859976	0.974603183686	0.452783155772	0.902222224960
84		0.062020281773	0.979523820536	0.448035337307	0.900740740476
85		0.068125368288	0.974126993664	0.449856181388	0.900000009272
86		0.067071490788	0.977619058556	0.466529821356	0.903333337219
87		0.065282328394	0.975873022799	0.454271275136	0.903703707236
88		0.071796920010	0.974603182740	0.446155679447	0.902222224960
89		0.059100964003	0.979523817698	0.458929557491	0.905185189512
90		0.066872688424	0.976666679458	0.455394300046	0.900370370459
91		0.058586023304	0.981269853456	0.454132090012	0.903333335011
92		0.057778357432	0.978730169554	0.459417083749	0.904074077253
93		0.067361442801	0.975555563730	0.460608129148	0.901851852735
94		0.057889721312	0.980317469627	0.469027897274	0.900370370459
95		0.061626659588	0.979682549598	0.476122802606	0.903333343841
96		0.059187824261	0.978571437654	0.471190683820	0.903703705028
97		0.058209092312	0.980000013397	0.474664722328	0.902592592769
98		0.048199816969	0.982063503492	0.479362337678	0.902592592769
99		0.057316318886	0.981269850617	0.483988076448	0.902592592769
100		0.051919234041	0.982063504439	0.478328911243	0.904444447270

max_length = 300
min_count=2, size=270, iter=10, sg=1, workers=10

LSTM(units=16, kernel_initializer=initializers.glorot_uniform(seed=1), activation='tanh', dropout=.2, recurrent_dropout=.1))
Dense(units=100, kernel_initializer=initializers.glorot_uniform(seed=1), activation='relu'))
Dense(units=100, kernel_initializer=initializers.glorot_uniform(seed=1), activation='relu'))
Dense(units=10, kernel_initializer=initializers.glorot_uniform(seed=1), activation='softmax'))

optimizer=optimizers.Adam(lr=.00087)

model.fit(x=train_x, y=train_y, epochs=epochs, validation_split=.3, batch_size=100, verbose=1)
